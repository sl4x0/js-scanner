# ==============================================================================
# ðŸ¦… JS SCANNER CONFIGURATION (Hunter-Architect Edition v3.5)
# Optimized for: Linux VPS + uvloop + TaskGroup + Hybrid Discovery
# ==============================================================================

# --- TARGETING & SCOPE ---
# Global timeout for HTTP requests (per URL)
timeout: 15 # Connection timeout in seconds (reduced for fail-fast behavior)
verify_ssl: false # Keep false for bug bounty (expired certs often host dev/staging)
max_file_size: 5242880 # 5 MB max to keep scans fast for bug bounty
max_file_size_mb_download: 5.0

# --- HYBRID DISCOVERY (The Funnel) ---

# 1. SPEED LAYER: Katana (Go Binary)
# Fastest discovery. Covers 80% of surface area.
katana:
  enabled: false
  depth: 2 # shallower for faster runs
  concurrency: 20 # reduced concurrency for stable runs
  rate_limit: 150 # lower RPS conservative default
  timeout: 60 # faster fail-fast for Katana
  # Custom flags appended to default: -silent -jc -kf all
  args: "-field-scope scope" # Ensure it stays in scope (redundant safety)

# 2. HISTORY LAYER: SubJS
# passive discovery of old/orphaned files
subjs:
  enabled: true
  timeout: 60 # Increased to ensure full archive query completion

# 3. INTELLIGENCE LAYER: Playwright (Browsers)
# Deep scan for lazy-loaded code. RAM intensive.
playwright:
  headless: true
  max_concurrent: 1 # FIX: Reduced from 2 to 1 - prevents browser crash race conditions!
  restart_after: 15 # FIX: Restart more frequently (was 20) to prevent memory buildup
  page_timeout: 30000 # CPU-OPTIMIZED: Reduced from 45s to 30s for faster fail-fast
  enable_interactions: false # âœ… FIX 3: DISABLED for speed - only downloading JS, no UI testing

# Performance Optimizations
interaction_delay: 0.3 # Ultra-fast interactions - reduced from 0.5s

# --- ANALYSIS & RECURSION ---

# 4. RECURSIVE DISCOVERY (Missing in original config)
# [CRITICAL] Analysis of found JS to find *more* JS (imports, requires)
recursion:
  enabled: true
  max_depth: 1 # âœ… FIX 3: Reduced from 2 to 1 - faster scans, less overhead
  validate_with_head: false # âœ… FIX 3: DISABLED - eliminates 25-75min validation overhead!

# 5. AST & EXTRACTION
ast:
  enabled: true
  max_file_size_mb: 100 # Increased for large webpack bundles

code_splitting:
  detect_dynamic_imports: true
  extract_chunk_map: true
  probe_common_locales: ["en", "es", "fr", "de"]

# --- PERFORMANCE TUNING (High-Performance VPS Optimized) ---

# Threading (Global)
# CRITICAL: 'threads' controls ACTUAL download concurrency
# âœ… CPU-OPTIMIZED: 10 threads per instance (7 instances Ã— 10 = 70 total)
threads: 10

# Batch Processing (The heavy lifting)
batch_processing:
  enabled: true
  # Phase 4: CPU Bound Processing
  process_threads: 3 # CPU-OPTIMIZED: Reduced from 10 to 3 for multi-instance usage
  cleanup_minified: false

# Download tuning - VPS-OPTIMIZED for stability over raw speed
download:
  chunk_size: 50 # âœ… FIX 1B: Reduced from 200 to 50 - prevent memory spikes
  skip_preflight: true # Skip HEAD requests for maximum speed - trust the URLs are valid
  max_concurrent_per_domain: 3 # âœ… FIX 1B: NEW - prevent rate limiting per domain

# Session Management (curl_cffi HTTP Client) - MAXIMUM SPEED CONFIG
# Optimized for high-bandwidth VPS with excellent connectivity
session_management:
  pool_size: 10 # CPU-OPTIMIZED: Match threads 1:1 (was 15 for 40 threads)
  rotate_after: 500 # Increased from 100 - keep connections alive longer
  download_timeout: 120 # âœ… FIX 1B: Increased from 60s to 120s - handle slow domains

# --- SECRET SCANNING ---

trufflehog_path: "" # Auto-detect
trufflehog_timeout: 300
# CPU Bottleneck Warning: TruffleHog is heavy.
trufflehog_max_concurrent: 5 # CPU-OPTIMIZED: Reduced from 10 to 5 for multi-instance usage

# --- ALERTING ---

discord_webhook: "https://discord.com/api/webhooks/1450082381934362726/IAgRuWMbRnzpHaAezmqVPJdg05L3yYe9nG48RCV5Io6ob9ekytIqpCYxQDg6z-ljO7M3"
discord_rate_limit: 60 # Don't spam your own webhook (60s between batches)
discord_status_enabled: false # Silence is golden. Only alerts matter.

notification_batching:
  strategy: "verified_immediate"
  batch_size: 25 # Larger batches for high-volume scans
  group_by_domain: true
  min_delay: 0.5 # Faster Discord updates

# --- LOGGING ---
logging:
  level: "INFO"
  file_enabled: true
  # Note: Code now auto-generates 'scan.log' (DEBUG) and 'errors.log' (WARNING)

# --- SYSTEM STABILITY ---

checkpoint:
  enabled: true
  frequency: 20 # Save less often to reduce disk I/O, rely on memory.
  auto_cleanup: true

retry:
  http_requests: 3 # âœ… FIX 3: Increased from 2 to 3 retries for better resilience
  backoff_base: 1.0 # âœ… FIX 3: Increased from 0.5s to 1.0s - give servers more time
  backoff_multiplier: 3.0 # âœ… NEW: Exponential backoff multiplier for aggressive scaling
  jitter: true

# --- BYPASS & EVASION ---

user_agent: "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36"
user_agents:
  - "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36"
  - "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36"
  - "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
  - "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36"
  - "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
  - "Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:121.0) Gecko/20100101 Firefox/121.0"
  - "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.1 Safari/605.1.15"
  - "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
  - "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36 Edg/120.0.0.0"
  - "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36"
  - "Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:120.0) Gecko/20100101 Firefox/120.0"
  - "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:121.0) Gecko/20100101 Firefox/121.0"

# --- TIMEOUTS ---
# âœ… FIX 3: Optimized timeout configuration for VPS and slow domains
timeouts:
  http_request: 30 # âœ… INCREASED from 15s to 30s - connection timeout for slow CDNs
  download_timeout: 90 # âœ… INCREASED from 20s to 90s - handle large bundles
  playwright_page: 45000 # âœ… INCREASED from 30s to 45s - slow SPA navigation
  trufflehog: 300

# âœ… FIX 3: Domain-specific timeout overrides (NEW SECTION)
# Domains that consistently timeout get special treatment
domain_timeouts:
  getsentry.net: 180 # 3x base timeout (always slow)
  collegeboard.org: 180
  watsons.com.cn: 180
  watsonsvip.com.cn: 180
  # Add more domains as discovered during scans

beautification:
  timeout_small: 120
  timeout_medium: 300
  timeout_large: 900
  timeout_xlarge: 1800

minification_detection:
  sample_size: 10000
  threshold_score: 5

bundle_unpacker:
  enabled: false
  min_file_size: 102400
  timeout: 300
  temp_dir: "temp/unpacked"

minimal_storage: false
max_concurrent_domains: 3 # âœ… FIX 3: Reduced from 5 to 3 - prevent domain parallelism overload

# ========================================
# v4.1 Performance Improvements (NEW)
# ========================================

# Bloom Filter (Optional - requires pybloom-live)
# Install: pip install pybloom-live
# Provides O(1) hash lookups for faster duplicate detection
bloom_filter:
  enabled: true # Auto-enabled if pybloom-live installed
  capacity: 500000 # Large capacity for mass scanning (auto-scales)
  error_rate: 0.001 # 0.1% false positive rate

# Noise Filter Thresholds (Configuration-Driven)
# Adjust these to control vendor library detection sensitivity
noise_filter:
  min_file_size_kb: 100 # Ignore tiny files (1KB -> 100KB for speed)
  max_newlines: 15 # Heuristic for minified code (tuned)

# Secrets Streaming (Automatic)
# Prevents memory exhaustion on large scans
secrets:
  buffer_size: 10 # Flush every N secrets to disk
  streaming_enabled: true # Always enabled (no config needed)

# Semgrep Static Analysis (v4.2 NEW)
# Requires: pip install semgrep && semgrep login
# Purpose: Fast security pattern detection in downloaded JS files
semgrep:
  enabled: true # Set to true after installing and logging in to Semgrep
  timeout: 360 # Maximum scan time in seconds (6 minutes default)
  max_target_bytes: 200000000 # Max file size to scan (200MB)
  jobs: 20 # Parallel jobs for faster scanning
  chunk_size: 50 # Number of files per semgrep subprocess to avoid timeouts/arglist limits
  ruleset: "p/javascript"
  max_files: 100 # Max number of files to scan with semgrep
  binary_path: "" # Optional: explicit path to semgrep binary (leave empty for auto-detect)
  # How long to wait for `semgrep --version` during validation (seconds)
  version_timeout: 30
  # Number of retries for the semgrep version check (helps on slow first-run startup)
  version_check_retries: 2
